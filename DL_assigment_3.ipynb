{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHpim3sZ3D7P",
        "outputId": "328539dc-70aa-4634-ae73-d4142395e44a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78f94e754410>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "wruQQTKr3Mzs"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weight = torch.rand(n_inputs, n_neurons)\n",
        "    self.bias = torch.rand(n_neurons)\n",
        "    self.outputs = None\n",
        "  def forward(self, inputs, activation = \"Softmax\"):\n",
        "    cur = inputs @ self.weight + self.bias\n",
        "    if activation == \"Relu\":\n",
        "      self.outputs = self.relu(cur)\n",
        "    elif activation == \"Sigmoid\":\n",
        "      self.outputs = self.sigmoid(cur)\n",
        "    else:\n",
        "      self.outputs = self.softmax(cur)\n",
        "    return self.outputs\n",
        "  def normalize(self, inputs):\n",
        "    return (inputs - torch.min(inputs)) / (torch.max(inputs) - torch.min(inputs))\n",
        "  def relu(self, inputs):\n",
        "    return torch.max(torch.tensor(0), inputs)\n",
        "  def sigmoid(self, inputs):\n",
        "    return 1 / (1 + torch.exp(-inputs))\n",
        "  def softmax(self, inputs):\n",
        "    return torch.exp(inputs) / torch.sum(torch.exp(inputs))\n",
        "  def categoricalCrossEntropy(self, y_true, y_predicted):\n",
        "      return torch.mean(-torch.sum(y_true * torch.log(y_predicted)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DONjeLXU8C_E",
        "outputId": "ca276933-721a-4676-c903-44c955436a61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8073, 0.0229, 0.2565, 0.2147],\n",
              "        [0.0752, 0.1878, 0.1430, 0.0822],\n",
              "        [0.5730, 0.2669, 0.5206, 0.4199],\n",
              "        [0.5344, 0.0458, 0.0899, 0.0479],\n",
              "        [0.8480, 0.5166, 0.0744, 0.3076],\n",
              "        [0.4948, 0.1691, 0.9045, 0.8588],\n",
              "        [0.6202, 0.4139, 0.7908, 0.6309],\n",
              "        [0.5426, 0.5617, 0.0648, 0.6416],\n",
              "        [0.6826, 0.8085, 0.7371, 0.9256],\n",
              "        [0.2342, 0.5410, 0.1318, 0.9293]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "input_data = torch.rand(10, 4)\n",
        "input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmM4v2TG7jBw",
        "outputId": "55e07d37-cdb6-434d-8eb2-dbb99e25e878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Cross-Entropy Loss:\n",
            "50.683746337890625\n",
            "The input layer is:\n",
            " tensor([[0.4767, 0.0679, 0.8241, 0.5590],\n",
            "        [0.3559, 0.9473, 0.2367, 0.2519],\n",
            "        [0.3284, 0.5573, 0.1115, 0.6081],\n",
            "        [0.0162, 0.2305, 0.2075, 0.1367],\n",
            "        [0.6146, 0.7197, 0.3777, 0.3498],\n",
            "        [0.5106, 0.0947, 0.0254, 0.1761],\n",
            "        [0.1375, 0.5705, 0.9036, 0.8568],\n",
            "        [0.1922, 0.7782, 0.9385, 0.3942],\n",
            "        [0.3370, 0.0276, 0.4640, 0.3063],\n",
            "        [0.6262, 0.0409, 0.4521, 0.5879]])\n",
            "The out put is: \n",
            " tensor([[0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378],\n",
            "        [0.0145, 0.0478, 0.0378]])\n"
          ]
        }
      ],
      "source": [
        "input_data = torch.rand(10, 4)\n",
        "input_layer = Model(4, 18)\n",
        "hidden1 = Model(18, 18)\n",
        "hidden2 = Model(18, 18)\n",
        "hidden3 = Model(18, 18)\n",
        "output = Model(18, 3)\n",
        "\n",
        "input = input_layer.forward(input_data, activation = \"Sigmoid\")\n",
        "hidden_1 = hidden1.forward(input, activation = \"Sigmoid\")\n",
        "hidden_2 = hidden2.forward(hidden_1, activation = \"Sigmoid\")\n",
        "hidden_3 = hidden3.forward(hidden_2, activation = \"Sigmoid\")\n",
        "# lets normalize before we use softmax\n",
        "output_ = output.forward(hidden3.normalize(hidden_3), activation=\"Softmax\")\n",
        "\n",
        "y_true = torch.randint(0, 2, (10, 3)).float()  # Binary classification for simplicity\n",
        "\n",
        "# Calculate categorical cross-entropy loss\n",
        "loss = output.categoricalCrossEntropy(y_true, output_)\n",
        "print(\"Categorical Cross-Entropy Loss:\")\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "print(\"The input layer is:\\n\", input_data)\n",
        "print(\"The out put is: \\n\", output_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ifJ5HzFh7-Rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5ed7d3-ef93-4a65-fc2c-80c20ac08818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Cross-Entropy Loss:\n",
            "64.38774108886719\n",
            "The input layer is:\n",
            " tensor([[0.6320, 0.4540, 0.5789, 0.2766],\n",
            "        [0.2107, 0.0935, 0.5407, 0.0408],\n",
            "        [0.0362, 0.9475, 0.7096, 0.4179],\n",
            "        [0.2673, 0.9424, 0.4784, 0.0833],\n",
            "        [0.8569, 0.9653, 0.5912, 0.8596],\n",
            "        [0.0992, 0.5138, 0.9902, 0.0082],\n",
            "        [0.0265, 0.5443, 0.6335, 0.6256],\n",
            "        [0.3571, 0.9175, 0.8619, 0.0061],\n",
            "        [0.0248, 0.9241, 0.2965, 0.5958],\n",
            "        [0.6766, 0.6150, 0.2421, 0.1592]])\n",
            "The out put is: \n",
            " tensor([[0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282],\n",
            "        [0.0132, 0.0586, 0.0282]])\n"
          ]
        }
      ],
      "source": [
        "input_data = torch.rand(10, 4)\n",
        "input_layer = Model(4, 18)\n",
        "hidden1 = Model(18, 18)\n",
        "hidden2 = Model(18, 18)\n",
        "hidden3 = Model(18, 18)\n",
        "output = Model(18, 3)\n",
        "input = input_layer.forward(input_data, activation = \"Sigmoid\")\n",
        "hidden_1 = hidden1.forward(input, activation = \"Sigmoid\")\n",
        "hidden_2 = hidden2.forward(hidden_1, activation = \"Sigmoid\")\n",
        "hidden_3 = hidden3.forward(hidden_2, activation = \"Sigmoid\")\n",
        "# lets normalize before we use softmax\n",
        "output_ = output.forward(hidden3.normalize(hidden_3), activation=\"Softmax\")\n",
        "\n",
        "y_true = torch.randint(0, 2, (10, 3)).float()  # Binary classification for simplicity\n",
        "\n",
        "# Calculate categorical cross-entropy loss\n",
        "loss = output.categoricalCrossEntropy(y_true, output_)\n",
        "print(\"Categorical Cross-Entropy Loss:\")\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "print(\"The input layer is:\\n\", input_data)\n",
        "print(\"The out put is: \\n\", output_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pRlPY522kb0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}