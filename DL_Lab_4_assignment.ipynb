{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "blA5esJtdFVP"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rurwL-W2PoIN"
      },
      "source": [
        "## Creating Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "owY9mN1oPAal"
      },
      "outputs": [],
      "source": [
        "class DenseLayer:\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajjr0QcUP8tA"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "6owCQofBP_iL"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = torch.max(torch.tensor(0),inputs)\n",
        "class Activation_Sigmoid:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = 1 / (1 + torch.exp(inputs*-1))\n",
        "class Activation_Softmax:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Get unnormalized probabilities\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "    self.output = probabilities\n",
        "class Activation_Linear:\n",
        "    def forward(self, inputs):\n",
        "        self.output = inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7usBC_5fprz"
      },
      "source": [
        "## Loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "-xWPtRUefp3j"
      },
      "outputs": [],
      "source": [
        "class Accuracy():\n",
        "  def calculate(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    accuracy = torch.mean((predictions == y_true).float())\n",
        "    return accuracy\n",
        "def MSE(y_true, y_pred):\n",
        "  return torch.mean(0.5*(y_true - y_pred)**2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([0.1, 0.5])\n",
        "y = torch.tensor([0.05,0.2, 0.45, 0.3])"
      ],
      "metadata": {
        "id": "7FZ7Pk0gIK8v"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_1 = DenseLayer(2, 4)\n",
        "activation1 = Activation_Sigmoid()\n",
        "output_layer = DenseLayer(4, 4)\n",
        "activation2 = Activation_Linear()"
      ],
      "metadata": {
        "id": "Cb5W0woZRU9_"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(X):\n",
        "  hidden_layer_1.forward(X)\n",
        "  activation1.forward(hidden_layer_1.output)\n",
        "  output_layer.forward(activation1.output)\n",
        "  activation2.forward(output_layer.output)\n",
        "  return activation2.output"
      ],
      "metadata": {
        "id": "WAoeJRRJRArn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_prop(fp):\n",
        "    lr = torch.tensor(0.01)\n",
        "    gradients_output = fp - y\n",
        "    output_layer.weights -= lr * torch.matmul(activation1.output.T, gradients_output)\n",
        "    output_layer.biases -= lr * gradients_output.sum(dim=0, keepdim=True)\n",
        "    gradients_hidden = torch.matmul(gradients_output, output_layer.weights.T) * activation1.output * (1 - activation1.output)\n",
        "    hidden_layer_1.weights -= lr * torch.matmul(X.reshape(-1, 1), gradients_hidden)\n",
        "    hidden_layer_1.biases -= lr * gradients_hidden.sum(dim=0, keepdim=True)\n"
      ],
      "metadata": {
        "id": "cJePM510S1HH"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 0.0001\n",
        "y_pred = forward_pass(X)\n",
        "err = MSE(y, y_pred)\n",
        "print(\"Initial loss:\", err)\n",
        "print(\"Initial prediction:\",y_pred)\n",
        "epoch = 1000\n",
        "for i in range(epoch):\n",
        "  back_prop(y_pred)\n",
        "  y_pred = forward_pass(X)\n",
        "  err = MSE(y, y_pred)\n",
        "  epoch += 1\n",
        "  if i%100 == 0:\n",
        "    # let me check the loss the prediction in every 100 iterations\n",
        "    print(\"-----------------------------------------\")\n",
        "    print(\"Current loss:\", err)\n",
        "    print(\"Current prediction:\",y_pred)\n",
        "    print(\"Target value:\",y)"
      ],
      "metadata": {
        "id": "taOHtItDTR28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80207b1-9156-42fd-a39c-9dee5dda096b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: tensor(0.0399)\n",
            "Initial prediction: tensor([[0.0103, 0.0057, 0.0096, 0.0071]])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(0.0383)\n",
            "Current prediction: tensor([[0.0111, 0.0096, 0.0184, 0.0130]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(0.0007)\n",
            "Current prediction: tensor([[0.0449, 0.1749, 0.3932, 0.2622]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(1.1344e-05)\n",
            "Current prediction: tensor([[0.0493, 0.1967, 0.4426, 0.2951]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(1.9338e-07)\n",
            "Current prediction: tensor([[0.0499, 0.1996, 0.4490, 0.2994]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(3.2958e-09)\n",
            "Current prediction: tensor([[0.0500, 0.1999, 0.4499, 0.2999]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(5.6140e-11)\n",
            "Current prediction: tensor([[0.0500, 0.2000, 0.4500, 0.3000]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(9.9735e-13)\n",
            "Current prediction: tensor([[0.0500, 0.2000, 0.4500, 0.3000]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(1.4488e-13)\n",
            "Current prediction: tensor([[0.0500, 0.2000, 0.4500, 0.3000]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(1.4488e-13)\n",
            "Current prediction: tensor([[0.0500, 0.2000, 0.4500, 0.3000]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n",
            "-----------------------------------------\n",
            "Current loss: tensor(1.4350e-13)\n",
            "Current prediction: tensor([[0.0500, 0.2000, 0.4500, 0.3000]])\n",
            "Target value: tensor([0.0500, 0.2000, 0.4500, 0.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = Accuracy()\n",
        "accuracy = acc.calculate(y_pred, y.unsqueeze(0))\n",
        "print(\"The accuracy is:\", accuracy)"
      ],
      "metadata": {
        "id": "chb9Oj0cCU2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94227a5-8cc9-4c0c-b228-1b5981065785"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2ZDsFbGKhTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}